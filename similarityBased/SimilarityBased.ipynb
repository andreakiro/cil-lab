{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "c0d982d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "e0df6782",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MOVIES = 1000\n",
    "N_USERS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "926e151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_matrix():\n",
    "    '''\n",
    "    Get the input matrix\n",
    "\n",
    "    Return\n",
    "    ----------\n",
    "    (data, W): (np.array(N_USERS, N_MOVIES), np.array(N_USERS, N_MOVIES))\n",
    "        The input array with the true ratings and Nan where no ratings where given and the \n",
    "        array containing 1 where the entries are given and 0 otherwise.\n",
    "    '''\n",
    "\n",
    "    data_pd = pd.read_csv('../data/data_train.csv') \n",
    "\n",
    "    # get users, movies\n",
    "    users, movies = [np.squeeze(arr) \n",
    "                    for arr in np.split(data_pd.Id.str.extract('r(\\d+)_c(\\d+)').values.astype(int) - 1, 2, axis=-1)]\n",
    "    # get predictions\n",
    "    predictions = data_pd.Prediction.values\n",
    "\n",
    "    # create data matrix\n",
    "    data = np.full((N_USERS, N_MOVIES), np.nan)\n",
    "    W = np.full((N_USERS, N_MOVIES), 0)\n",
    "\n",
    "    # populate data matrix\n",
    "    for user, movie, pred in zip(users, movies, predictions): \n",
    "        data[user][movie] = pred\n",
    "        W[user][movie] = 1 if not math.isnan(pred) else 0\n",
    "    \n",
    "    return (data, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "c4f3283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, W = get_input_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "c0042381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "c8797ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(X, user=True):\n",
    "    '''\n",
    "    Compute the cosine similarity between every pair of users or items\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.array(N_USERS, N_MOVIES)\n",
    "        The matrix with ratings.\n",
    "        \n",
    "    user : bool, default True\n",
    "           a boolean which says whether we want to compute the cosine similarity between every users or \n",
    "           between every items.\n",
    "\n",
    "    Return\n",
    "    ----------\n",
    "    similarity: np.array(N_USERS, N_USERS) if user = True else np.array(N_MOVIES, N_MOVIES):\n",
    "                The similarity score (between -1 and 1 if X has negative values, where -1 means two vectors \n",
    "                going in the opposite direction or between 0 and 1 if we only have positive values where 0 means\n",
    "                orthogonal vectors) for each user-user or item-item pair. The returned matrix is therefore \n",
    "                symmetric.\n",
    "    '''\n",
    "    X = np.nan_to_num(X) # Replace Nan by 0 (the dot product will hence be 0, what we want)\n",
    "    \n",
    "    if not user:\n",
    "        X = X.T\n",
    "    \n",
    "    similarity = np.zeros((X.shape[0], X.shape[0]))\n",
    "    for i,user in enumerate(X):\n",
    "        \n",
    "        similarity[i, :] = (X@user)/(np.linalg.norm(X, axis=1)*np.linalg.norm(user))\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "c20cd6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pearson_correlation_coefficient(X, user=True, statistic_to_use=\"mean\"):\n",
    "    '''\n",
    "    Compute the pearson correlation coefficient between every pair of users or items\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.array(N_USERS, N_MOVIES)\n",
    "        The matrix with ratings.\n",
    "        \n",
    "    user : bool, default True\n",
    "           a boolean which says whether we want to compute the cosine similarity between every users or \n",
    "           between every items.\n",
    "    statistic_to_use: String, either 'mean' or 'median', default 'mean'\n",
    "                      The method use to center the data points.\n",
    "\n",
    "    Return\n",
    "    ----------\n",
    "    similarity: np.array(N_USERS, N_USERS) if user = True else np.array(N_MOVIES, N_MOVIES):\n",
    "                The similarity score (between -1 and 1) for each user-user or item-item pair.\n",
    "                The returned matrix is therefore symmetric.\n",
    "    '''\n",
    "    if not user:\n",
    "        X = X.T\n",
    "    \n",
    "    if statistic_to_use == \"mean\":\n",
    "        statistic = np.nanmean(X, axis=1)\n",
    "    elif statistic_to_use == \"median\":\n",
    "        statistic = np.nanmedian(X, axis=1)\n",
    "    else:\n",
    "        raise ValueError(f\"{statistic_to_use} is not a valid statistic! Should be 'mean' or 'median'\")\n",
    "    \n",
    "    centered_X = X-statistic.reshape(-1,1)\n",
    "    \n",
    "    return compute_cosine_similarity(centered_X, user=True) # Always True since we have already taken the transpose in this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "8e66a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_SigRA(X, W, user=True):\n",
    "    '''\n",
    "    Compute the SiGra (https://ieeexplore.ieee.org/document/8250351) similarity between every pair of users or \n",
    "    items. Note that this method already uses weighting and hence should not be followed by the \n",
    "    similarity_weighting function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.array(N_USERS, N_MOVIES)\n",
    "        The matrix with ratings.\n",
    "    \n",
    "    W : np.array(N_USERS, N_MOVIES):\n",
    "        The mask containing 1 for rated items and 0 for unrated items.\n",
    "        \n",
    "    user : bool, default True\n",
    "           a boolean which says whether we want to compute the cosine similarity between every users or \n",
    "           between every items.\n",
    "\n",
    "    Return\n",
    "    ----------\n",
    "    similarity: np.array(N_USERS, N_USERS) if user = True else np.array(N_MOVIES, N_MOVIES):\n",
    "                The similarity score for each user-user or item-item pair.\n",
    "                The returned matrix is therefore symmetric.\n",
    "    '''    \n",
    "    if not user:\n",
    "        X = X.T\n",
    "        W = W.T\n",
    "    \n",
    "    similarity = np.zeros((X.shape[0], X.shape[0]))\n",
    "\n",
    "    number_ratings = np.sum(W, axis=1)\n",
    "    \n",
    "    for i, (uw, ux) in enumerate(zip(W, X)):\n",
    "        for j, (vw, vx) in enumerate(zip(W, X)):\n",
    "            common_ratings = np.logical_and(uw, vw)\n",
    "            number_common_ratings = np.sum(common_ratings)\n",
    "            if number_common_ratings == 0:\n",
    "                similarity[i, j] = 0\n",
    "            else:\n",
    "                ratios_sum = np.sum(np.minimum(ux[common_ratings], vx[common_ratings])/np.maximum(ux[common_ratings], vx[common_ratings]))\n",
    "                weight = 1.0/(1+np.exp(-(number_ratings[i] + number_ratings[j])/(2*number_common_ratings))) #Why number_common_ratings in the denominator? Would make more sense to inverse numerator and denominator, but like that in the paper\n",
    "                similarity[i, j] = weight*ratios_sum/number_common_ratings\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "6a35ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_weighting(similarity, W, method=\"weighting\", threshold=10):\n",
    "    '''\n",
    "    Weight the similarity matrix based on the number of ratings of each entry. Without weighting, users having \n",
    "    just few entries are often considered as closer, which this method tries to prevent.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    similarity : np.array(N_USERS, N_USERS) or np.array(N_MOVIES, N_MOVIES)\n",
    "                 The matrix with similarity between users or movies\n",
    "        \n",
    "    W : np.array(N_USERS, N_MOVIES):\n",
    "        The mask containing 1 for rated items and 0 for unrated items.\n",
    "        \n",
    "    method: String, either 'weighting', 'significance' or 'sigmoid', default 'weighting'\n",
    "                      The method use to weight the similarity.\n",
    "                      Weighting weights all entries based on the number of common rated items and number of rated items.\n",
    "                      Significance only reduce importance when number of common rated items is below the threshold.\n",
    "                      Sigmoid reduce weight when users have only few common rated items. It keeps most of the similarity\n",
    "                      measure almost untouched and hence is the softest weighting method.\n",
    "    \n",
    "    threshold: int, default 10\n",
    "               Only used if method is 'significance'. Minimum number of common rated items needed to not have\n",
    "               a decrease in importance. Needs to be adapted depending on the number of common users/items. For\n",
    "               user-based similarity, should be around 7, for item-based similarity, around 70. \n",
    "               TODO: read paper to have more knowledge about what a good threshold is.\n",
    "\n",
    "    Return\n",
    "    ----------\n",
    "    weighted_similarity: np.array(N_USERS, N_USERS) or np.array(N_MOVIES, N_MOVIES) depending of shape of similarity:\n",
    "                The weighted similarity score (between -1 and 1) for each user-user or item-item pair.\n",
    "                The returned matrix is therefore symmetric.\n",
    "    '''\n",
    "    assert (similarity.shape[0] == W.shape[0] or similarity.shape[0] == W.shape[1]) and similarity.shape[0] == similarity.shape[1]\n",
    "    \n",
    "    weighted_similarity = np.zeros_like(similarity)\n",
    "    if similarity.shape[0] != W.shape[0]:\n",
    "        W=W.T # We were using the items and not the users for the similarity\n",
    "    \n",
    "    number_ratings = np.sum(W, axis=1)\n",
    "    \n",
    "    for i, u in enumerate(W):\n",
    "        for j, v in enumerate(W):\n",
    "            number_common_ratings = np.sum(np.logical_and(u, v))\n",
    "            \n",
    "            if method == \"weighting\":\n",
    "                weight = 2*number_common_ratings/(number_ratings[i] + number_ratings[j]) if (number_ratings[i] + number_ratings[j]) != 0 else 0\n",
    "            elif method == \"significance\":\n",
    "                weight = np.minimum(number_common_ratings, threshold)/threshold\n",
    "            elif method == \"sigmoid\":\n",
    "                weight = 1.0/(1+np.exp(-number_common_ratings/2))\n",
    "            else:\n",
    "                raise ValueError(f\"{method} is not a valid method! Should be 'weighting', 'significance' or 'sigmoid'\")\n",
    "\n",
    "            weighted_similarity[i, j] = weight*similarity[i, j]\n",
    "    \n",
    "    return weighted_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a33d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = compute_cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "cc43d755",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_items = compute_cosine_similarity(X, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2bc8bd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ...,  1., -1., -1.],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, -1.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_pearson_correlation_coefficient(X, statistic_to_use=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e09c2739",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_items_pearson=compute_pearson_correlation_coefficient(X, False, statistic_to_use=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8f9e935d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.02009841,  0.04217509, ...,  0.02842744,\n",
       "         0.0526932 ,  0.03357856],\n",
       "       [-0.02009841,  1.        , -0.01603365, ..., -0.02378553,\n",
       "         0.00502976,  0.02908714],\n",
       "       [ 0.04217509, -0.01603365,  1.        , ...,  0.05456939,\n",
       "         0.04203638, -0.01824104],\n",
       "       ...,\n",
       "       [ 0.02842744, -0.02378553,  0.05456939, ...,  1.        ,\n",
       "         0.08803759,  0.01628506],\n",
       "       [ 0.0526932 ,  0.00502976,  0.04203638, ...,  0.08803759,\n",
       "         1.        ,  0.03081192],\n",
       "       [ 0.03357856,  0.02908714, -0.01824104, ...,  0.01628506,\n",
       "         0.03081192,  1.        ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_items_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6893b80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.09305098, 0.1306107 , ..., 0.08812148, 0.15839492,\n",
       "        0.12179982],\n",
       "       [0.09305098, 1.        , 0.11384168, ..., 0.08535064, 0.11111508,\n",
       "        0.14269472],\n",
       "       [0.1306107 , 0.11384168, 1.        , ..., 0.10391016, 0.13360448,\n",
       "        0.1435644 ],\n",
       "       ...,\n",
       "       [0.08812148, 0.08535064, 0.10391016, ..., 1.        , 0.16871144,\n",
       "        0.14879859],\n",
       "       [0.15839492, 0.11111508, 0.13360448, ..., 0.16871144, 1.        ,\n",
       "        0.20594874],\n",
       "       [0.12179982, 0.14269472, 0.1435644 , ..., 0.14879859, 0.20594874,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "45b42687",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_similarity = weight_similarity(similarity_items, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "21dd8fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_similarity = similarity_weighting(similarity_items, W, method=\"significance\", threshold=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "c2411482",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_similarity = similarity_weighting(similarity_items, W, method=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4216335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "similartiry_items_SiGra = compute_SigRA(X, W, user=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ff45d5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73105858, 0.72079709, 0.73050547, ..., 0.68383528, 0.72625998,\n",
       "        0.78522803],\n",
       "       [0.72079709, 0.73105858, 0.68952065, ..., 0.67338861, 0.74773731,\n",
       "        0.75743673],\n",
       "       [0.73050547, 0.68952065, 0.73105858, ..., 0.71954167, 0.76983944,\n",
       "        0.69953118],\n",
       "       ...,\n",
       "       [0.68383528, 0.67338861, 0.71954167, ..., 0.73105858, 0.77151787,\n",
       "        0.71935246],\n",
       "       [0.72625998, 0.74773731, 0.76983944, ..., 0.77151787, 0.73105858,\n",
       "        0.75868866],\n",
       "       [0.78522803, 0.75743673, 0.69953118, ..., 0.71935246, 0.75868866,\n",
       "        0.73105858]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similartiry_items_SiGra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "8582da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_predict(X, W, similarity, k=10, with_std = False, verbose=True):\n",
    "    '''\n",
    "    Predict the missing values by a weighted average of the ratings of the k nearest neighbors with a weight \n",
    "    corresponding to their similarity. Take into account the mean value of the user (respectively item)\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.array(N_USERS, N_MOVIES)\n",
    "        The matrix with ratings.\n",
    "    \n",
    "    W : np.array(N_USERS, N_MOVIES):\n",
    "        The mask containing 1 for rated items and 0 for unrated items.\n",
    "    \n",
    "    similarity : np.array(N_USERS, N_USERS) or np.array(N_MOVIES, N_MOVIES)\n",
    "                 The matrix with similarity between users or movies\n",
    "        \n",
    "    k: int, default 10\n",
    "       Number of nearest neighbors\n",
    "    \n",
    "    with_std: bool, default False\n",
    "              If set to true, take into account the std to compute a Z-score when computing the weights\n",
    "\n",
    "    verbose: bool, default True:\n",
    "             If set to True, print update messages\n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    predictions: np.array(N_USERS, N_MOVIES)\n",
    "                 The predictions for the missing values\n",
    "    '''\n",
    "    was_transposed=False\n",
    "    printing_interval=200\n",
    "    \n",
    "    if similarity.shape[0] != W.shape[0]: # We were using the items and not the users for the similarity \n",
    "        was_transposed=True\n",
    "        W=W.T   \n",
    "        X=X.T\n",
    "        printing_interval=30\n",
    "    \n",
    "    predictions = X.copy()\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            if not W[i, j]:\n",
    "                user_mean = np.nanmean(X[i, :])\n",
    "                possible_neighbors = np.where(W[:, j])[0]\n",
    "                sorted_possible_neighbors = possible_neighbors[np.flip(np.argsort(similarity[i, possible_neighbors]))]\n",
    "                nearest_neighbors = sorted_possible_neighbors[:k] \n",
    "                \n",
    "                if with_std:\n",
    "                    number_items_rated = np.sum(W[i, :])\n",
    "                    \n",
    "                    user_std = np.sqrt(np.sum((X[i, W[i, :]]-user_mean)**2)/(number_items_rated-1)) if number_items_rated > 1 else 1\n",
    "                    neighbors_means = np.nanmean(X[nearest_neighbors, :], axis=1)\n",
    "                    \n",
    "                    neighbors_number_item_rated = np.sum(W[nearest_neighbors, :], axis=1)\n",
    "                    neighbors_number_item_rated[neighbors_number_item_rated<=1]=2 #To avoid division by 0 problems, should not happen frequently, set std to 1 later\n",
    "                    \n",
    "                    neighbors_stds = np.sqrt(np.sum((X[nearest_neighbors, :][W[nearest_neighbors, :]]-neighbors_means)**2, axis=1)/(neighbors_number_item_rated-1))\n",
    "                    neighbors_stds[neighbors_number_item_rated<=1] = 1 #Set std to 1 if it was the only rating\n",
    "                    \n",
    "                    predictions[i, j] = user_mean + user_std * np.sum(np.multiply(similarity[i, nearest_neighbors], (X[nearest_neighbors, j]-np.nanmean(X[nearest_neighbors, :], axis=1))/neighbors_stds))/np.sum(similarity[i, nearest_neighbors])\n",
    "                else:  \n",
    "                    predictions[i, j] = user_mean + np.sum(np.multiply(similarity[i, nearest_neighbors], X[nearest_neighbors, j]-np.nanmean(X[nearest_neighbors, :], axis=1)))/np.sum(similarity[i, nearest_neighbors])\n",
    "                \n",
    "        if verbose and (i==X.shape[0]-1 or (not i%printing_interval and i!=0)):\n",
    "            similarity_type = \"user\" if not was_transposed else \"item\"\n",
    "            print(f\"Done with {similarity_type} {i}/{X.shape[0]}\")\n",
    "            \n",
    "    return predictions.T if was_transposed else predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "1e1a0884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with row 30/1000\n",
      "Done with row 60/1000\n",
      "Done with row 90/1000\n",
      "Done with row 120/1000\n",
      "Done with row 150/1000\n",
      "Done with row 180/1000\n",
      "Done with row 210/1000\n",
      "Done with row 240/1000\n",
      "Done with row 270/1000\n",
      "Done with row 300/1000\n",
      "Done with row 330/1000\n",
      "Done with row 360/1000\n",
      "Done with row 390/1000\n",
      "Done with row 420/1000\n",
      "Done with row 450/1000\n",
      "Done with row 480/1000\n",
      "Done with row 510/1000\n",
      "Done with row 540/1000\n",
      "Done with row 570/1000\n",
      "Done with row 600/1000\n",
      "Done with row 630/1000\n",
      "Done with row 660/1000\n",
      "Done with row 690/1000\n",
      "Done with row 720/1000\n",
      "Done with row 750/1000\n",
      "Done with row 780/1000\n",
      "Done with row 810/1000\n",
      "Done with row 840/1000\n",
      "Done with row 870/1000\n",
      "Done with row 900/1000\n",
      "Done with row 930/1000\n",
      "Done with row 960/1000\n",
      "Done with row 990/1000\n",
      "Done with row 999/1000\n"
     ]
    }
   ],
   "source": [
    "pred = weighted_average_predict(X, W, sigmoid_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "c1565ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(pred, submission_name=\"submission\", compression_type =\"zip\"):\n",
    "    sample = pd.read_csv('../data/sampleSubmission.csv') # load sample submission\n",
    "    sample = sample.astype({\"Prediction\": float}, errors='raise')\n",
    "    for index, row in sample.iterrows():\n",
    "        r, c = re.findall(r'r(\\d+)_c(\\d+)', row[\"Id\"])[0]\n",
    "        sample.at[index, \"Prediction\"] = pred[int(r)-1][int(c)-1]\n",
    "    \n",
    "    sample.to_csv(submission_name, compression=compression_type, float_format='%.3f', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "585f3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_on_kaggle(name=\"submission.zip\", message=None):\n",
    "    '''\n",
    "    Submit a solution on kaggle.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name: str (optional)\n",
    "        name of the file to submit\n",
    "    message: str (optional)\n",
    "        Message to use with the submission. Makes easier to \n",
    "        understand what each submission is about\n",
    "    '''\n",
    "    command = f\"kaggle competitions submit -c cil-collaborative-filtering-2022 -f {name}\"\n",
    "\n",
    "    if not message is None:\n",
    "        command = command + f\" -m {message}\"\n",
    "\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "9b8b995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission(pred, submission_name=\"sigmoid_cosine_similarity_items_10nn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "7bc620e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_on_kaggle(name=\"sigmoid_cosine_similarity_items_10nn\", message=\"Similarity based using items, cosine similarity with sigmoid weighting and 10 nearest neighbors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "8111e33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.48457718, 3.46575115, 3.29454848, ..., 2.79584825, 2.99129092,\n",
       "        3.33164412],\n",
       "       [3.34920169, 2.47014907, 2.84239086, ..., 5.        , 3.        ,\n",
       "        3.        ],\n",
       "       [2.27405046, 3.02060159, 2.87631228, ..., 2.10074353, 2.37203414,\n",
       "        2.56367779],\n",
       "       ...,\n",
       "       [2.91337448, 3.36292369, 3.19491513, ..., 2.76052163, 2.91109604,\n",
       "        3.4841525 ],\n",
       "       [2.80468284, 3.44195667, 3.54328259, ..., 2.66757643, 2.83965279,\n",
       "        3.04405327],\n",
       "       [2.87667227, 3.44069647, 3.30077702, ..., 2.98914642, 3.08887743,\n",
       "        3.        ]])"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f4dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
